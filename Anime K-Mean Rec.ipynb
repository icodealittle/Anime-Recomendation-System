{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import *\n",
    "from statistics import mean\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import sys\n",
    "from sys import exc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating_data_df = pd.read_csv('./datasets/user_score_data.csv', usecols=['user_id', 'mal_id', 'rating'], \n",
    "                                  dtype={'user_id':'int32', 'mal_id':'int32', 'rating':'float32'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the datset that only contain 4+ rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = user_rating_data_df[user_rating_data_df['rating'] >= 4.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_movies = ratings.loc[:, ['user_id', 'mal_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_movies = ratings.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_movies.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav_movies.to_csv('./datasets/filtered_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moviesList(users, users_data):\n",
    "    # users = a list of users IDs\n",
    "    # users_data = a dataframe of users favourite movies or users watched movies\n",
    "    users_movies_list = []\n",
    "    for u in users:\n",
    "        users_movies_list.append(str(list(users_data[users_data['user_id'] == u]['mal_id'])).split('[')[1].split(']')[0])\n",
    "    return users_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.unique(fav_movies['user_id'])\n",
    "print(users.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_movies_list = moviesList(users, fav_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SparseMatrix(list_of_str):\n",
    "    # list_of_str = A list, which contain strings of users favourite movies separate by comma \",\".\n",
    "    # It will return us sparse matrix and feature names on which sparse matrix is defined \n",
    "    # i.e. name of movies in the same order as the column of sparse matrix\n",
    "    cv = CountVectorizer(token_pattern = r'[^\\,\\ ]+', lowercase = False)\n",
    "    sparseMatrix = cv.fit_transform(list_of_str)\n",
    "    return sparseMatrix.toarray(), cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparseMatrix, feature_names = SparseMatrix(users_movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sparse = pd.DataFrame(sparseMatrix, index = users, columns = feature_names)\n",
    "df_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_6_users_SM = fav_movies[fav_movies['user_id'].isin(users[:6])].sort_values('user_id')\n",
    "first_6_users_SM.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sparse.loc[np.unique(first_6_users_SM['user_id']), list(map(str, np.unique(first_6_users_SM['mal_id'])))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Mean CLustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=15, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "clusters = kmeans.fit_predict(sparseMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_cluster = pd.DataFrame(np.concatenate((users.reshape(-1,1), clusters.reshape(-1,1)), axis = 1), columns = ['user_id', 'Cluster'])\n",
    "users_cluster.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustersMovies(users_cluster, users_data):\n",
    "    clusters = list(users_cluster['Cluster'])\n",
    "    each_cluster_movies = list()\n",
    "    for i in range(len(np.unique(clusters))):\n",
    "        users_list = list(users_cluster[users_cluster['Cluster'] == i]['user_id'])\n",
    "        users_movies_list = list()\n",
    "        for user in users_list:    \n",
    "            users_movies_list.extend(list(users_data[users_data['user_id'] == user]['mal_id']))\n",
    "        users_movies_counts = list()\n",
    "        users_movies_counts.extend([[movie, users_movies_list.count(movie)] for movie in np.unique(users_movies_list)])\n",
    "        each_cluster_movies.append(pd.DataFrame(users_movies_counts, columns=['mal_id', 'Count']).sort_values(by = ['Count'], ascending = False).reset_index(drop=True))\n",
    "    return each_cluster_movies\n",
    "cluster_movies = clustersMovies(users_cluster, fav_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_movies[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    len_users = users_cluster[users_cluster['Cluster'] == i].shape[0]\n",
    "    print('Users in Cluster ' + str(i) + ' -> ', len_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user favourite movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userFav(user_id, users_data):\n",
    "    return list(users_data[users_data['user_id'] == user_id]['mal_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixClusters(clusters_movies_dataframes, users_cluster_dataframe, users_data, smallest_cluster_size = 11):\n",
    "    # clusters_movies_dataframes: will be a list which will contain each dataframes of each cluster movies\n",
    "    each_cluster_movies = clusters_movies_dataframes.copy()\n",
    "    users_cluster = users_cluster_dataframe.copy()\n",
    "    # Let convert dataframe in each_cluster_movies to list with containing only movies IDs\n",
    "    each_cluster_movies_list = [list(df['mal_id']) for df in each_cluster_movies]\n",
    "    # First we will prepair a list which containt lists of users in each cluster -> [[Cluster 0 Users], [Cluster 1 Users], ... ,[Cluster N Users]] \n",
    "    usersInClusters = list()\n",
    "    total_clusters = len(each_cluster_movies)\n",
    "    for i in range(total_clusters):\n",
    "        usersInClusters.append(list(users_cluster[users_cluster['Cluster'] == i]['user_id']))\n",
    "    uncategorizedUsers = list()\n",
    "    i = 0\n",
    "    # Now we will remove small clusters and put their users into another list named \"uncategorizedUsers\"\n",
    "    # Also when we will remove a cluster, then we have also bring back cluster numbers of users which comes after deleting cluster\n",
    "    for j in range(total_clusters):\n",
    "        if len(usersInClusters[i]) < smallest_cluster_size:\n",
    "            uncategorizedUsers.extend(usersInClusters[i])\n",
    "            usersInClusters.pop(i)\n",
    "            each_cluster_movies.pop(i)\n",
    "            each_cluster_movies_list.pop(i)\n",
    "            users_cluster.loc[users_cluster['Cluster'] > i, 'Cluster'] -= 1\n",
    "            i -= 1\n",
    "        i += 1\n",
    "    for user in uncategorizedUsers:\n",
    "        elemProbability = list()\n",
    "        user_movies = userFav(user, users_data)\n",
    "        if len(user_movies) == 0:\n",
    "            print(user)\n",
    "        user_missed_movies = list()\n",
    "        for movies_list in each_cluster_movies_list:\n",
    "            count = 0\n",
    "            missed_movies = list()\n",
    "            for movie in user_movies:\n",
    "                if movie in movies_list:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    missed_movies.append(movie)\n",
    "            elemProbability.append(count / len(user_movies))\n",
    "            user_missed_movies.append(missed_movies)\n",
    "        user_new_cluster = np.array(elemProbability).argmax()\n",
    "        users_cluster.loc[users_cluster['user_id'] == user, 'Cluster'] = user_new_cluster\n",
    "        if len(user_missed_movies[user_new_cluster]) > 0:\n",
    "            each_cluster_movies[user_new_cluster] = each_cluster_movies[user_new_cluster].append([{'mal_id': new_movie, 'Count': 1} for new_movie in user_missed_movies[user_new_cluster]], ignore_index = True)\n",
    "    return each_cluster_movies, users_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_fixed, clusters_fixed = fixClusters(cluster_movies, users_cluster, fav_movies, smallest_cluster_size = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class saveLoadFiles:\n",
    "    def save(self, filename, data):\n",
    "        try:\n",
    "            file = open('datasets/' + filename + '.pkl', 'wb')\n",
    "            pickle.dump(data, file)\n",
    "        except:\n",
    "            err = 'Error: {0}, {1}'.format(exc_info()[0], exc_info()[1])\n",
    "            print(err)\n",
    "            file.close()\n",
    "            return [False, err]\n",
    "        else:\n",
    "            file.close()\n",
    "            return [True]\n",
    "    def load(self, filename):\n",
    "        try:\n",
    "            file = open('datasets/' + filename + '.pkl', 'rb')\n",
    "        except:\n",
    "            err = 'Error: {0}, {1}'.format(exc_info()[0], exc_info()[1])\n",
    "            print(err)\n",
    "            file.close()\n",
    "            return [False, err]\n",
    "        else:\n",
    "            data = pickle.load(file)\n",
    "            file.close()\n",
    "            return data\n",
    "    def load_Dataset(self):\n",
    "        return self.load('clusters_movies_dataset')\n",
    "    def save_Dataset(self, data):\n",
    "        return self.save('clusters_movies_dataset', data)\n",
    "    def load_Clusters(self):\n",
    "        return self.load('users_clusters')\n",
    "    def save_Clusters(self, data):\n",
    "        return self.save('users_clusters', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveLoadFile = saveLoadFiles()\n",
    "load_movies_list, load_users_clusters = saveLoadFile.load_Dataset(), saveLoadFile.load_Clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Class Function for the recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class userRequestedFor:\n",
    "    def __init__(self, user_id, users_data):\n",
    "        self.users_data = users_data.copy()\n",
    "        self.user_id = user_id\n",
    "        # Find User Cluster\n",
    "        users_cluster = saveLoadFiles().load_Clusters()\n",
    "        self.user_cluster = int(users_cluster[users_cluster['user_id'] == self.user_id]['Cluster'])\n",
    "        # Load User Cluster Movies Dataframe\n",
    "        self.movies_list = saveLoadFiles().load_Dataset()\n",
    "        self.cluster_movies = self.movies_list[self.user_cluster] # dataframe\n",
    "        self.cluster_movies_list = list(self.cluster_movies['mal_id']) # list\n",
    "    def updatedFavouriteMoviesList(self, new_movie_Id):\n",
    "        if new_movie_Id in self.cluster_movies_list:\n",
    "            self.cluster_movies.loc[self.cluster_movies['mal_id'] == new_movie_Id, 'Count'] += 1\n",
    "        else:\n",
    "            self.cluster_movies = self.cluster_movies.append([{'user_id': new_movie_Id, 'Count': 1}], ignore_index=True)\n",
    "        self.cluster_movies.sort_values(by = ['Count'], ascending = False, inplace= True)\n",
    "        self.movies_list[self.user_cluster] = self.cluster_movies\n",
    "        saveLoadFiles().save_Dataset(self.movies_list)\n",
    "\n",
    "    def recommendMostGenres(self):\n",
    "        try:\n",
    "            user_movies = userFav(self.user_id, self.users_data)\n",
    "            cluster_movies_list = self.cluster_movies_list.copy()\n",
    "            for user_movie in user_movies:\n",
    "                if user_movie in cluster_movies_list:\n",
    "                    cluster_movies_list.append(user_movie)\n",
    "            return [True, cluster_movies_list]\n",
    "        except KeyError:\n",
    "            err = \"User history does not exist\"\n",
    "            print(err)\n",
    "            return [False, err]\n",
    "        except:\n",
    "            err = 'Error: {0}, {1}'.format(exc_info()[0], exc_info()[1])\n",
    "            print(err)\n",
    "            return [False, err]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging both dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animes_df = pd.read_csv('./datasets/anime_data.csv', usecols=['mal_id', 'title', 'genres'])\n",
    "animes_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fav_movies.merge(animes_df, on = 'mal_id')\n",
    "df = df.drop_duplicates(['user_id','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie histories based on user_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = list(df.loc[df['user_id'] == 55]['title'])\n",
    "if title != []:\n",
    "    print('Movie title: ', title, ', Genres: ', end = '')\n",
    "    genres = ast.literal_eval(df.loc[df['user_id'] == 55]['genres'].values[0].split('[')[1].split(']')[0])\n",
    "    for genre in genres:\n",
    "        print(genre[:7], ' ', end = '')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement users recommendation based on their genres and anime history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = userRequestedFor(2, fav_movies).recommendMostGenres()[1]\n",
    "for movie in rec[:1]:\n",
    "    title = list(df.loc[df['user_id'] == 2]['title'])\n",
    "    if title != []:\n",
    "        genres = ast.literal_eval(df.loc[df['user_id'] == 2]['genres'].values[0].split('[')[1].split(']')[0])\n",
    "        for genre in genres:\n",
    "            print(genre[:20], ' ', end = '')\n",
    "        print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top anime that the user is most likely to watch can be obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_rec = df['title'].values\n",
    "\n",
    "anime_rec_list = []\n",
    "for rec in anime_rec:\n",
    "    if rec not in anime_rec_list:\n",
    "        anime_rec_list.append(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_rec_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
